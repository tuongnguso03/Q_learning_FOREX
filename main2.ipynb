{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from environment import ForexEnv\n",
    "from model import Model\n",
    "import pandas as pd\n",
    "from data_processing import dataset_with_indicators, print_bins\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = pd.read_csv('forex_data_train_1987-2017.csv')\n",
    "dataset_with_indicators()\n",
    "environment = ForexEnv(df)\n",
    "print(environment.state)\n",
    "#agent = Model()\n",
    "agent = Model(load=\"test/100k_8maxscore_2datasets.pickle\")\n",
    "#agent = Model(load=\"Q_value_test_100.pickle\")\n",
    "#print(agent.Q_values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "((1.1269, 11.4137), 0)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '100k_8maxscore_2datasets.pickle'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(environment\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#agent = Model()\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m100k_8maxscore_2datasets.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Courses/AI/Q_learning_FOREX-main/model.py:10\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ_values \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;241m0\u001b[39m, pickle\u001b[38;5;241m.\u001b[39mload(handle))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '100k_8maxscore_2datasets.pickle'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(agent.Q_values))\n",
    "print_bins()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = ForexEnv(df)\n",
    "#agent.Q_learning(env, 200, alpha=0.1, exploration=0.9, discount=0.9)\n",
    "#agent.Q_learning(env, 110, alpha=0.01, exploration=0.9, discount=0.9)\n",
    "agent.Q_learning(env, 300, alpha=0.05, exploration=0.99, discount=0.99)\n",
    "#agent.Q_learning(env, 200, alpha=0.1, exploration=0.9, discount=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = ForexEnv(df)\n",
    "agent.Q_learning(env, iterations=1, alpha=0, exploration=0, discount=0, debug=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(env.rewards_memory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_test = pd.read_csv(\"forex_data_2017.csv\").reset_index(drop=True)\n",
    "env_test = ForexEnv(df_test)\n",
    "#agent.Q_learning(env_test, 1, alpha=0, exploration=0, discount=0, debug=True)\n",
    "for i in range(10):\n",
    "    if i >= 0:\n",
    "        agent.Q_learning(env_test, iterations=1, alpha=0, exploration=0, discount=0, debug=True)\n",
    "        plt.plot(env_test.asset_memory,'r')\n",
    "        a = 'png_test/account_value_test.png'\n",
    "        plt.savefig(a[:-4] + str(i) + '.png')\n",
    "        plt.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration  0\n",
      "end_total_asset:1011041.2200000006\n",
      "Iteration  0\n",
      "end_total_asset:1011256.5740000004\n",
      "Iteration  0\n",
      "end_total_asset:1011546.3280000006\n",
      "Iteration  0\n",
      "end_total_asset:1011570.5760000007\n",
      "Iteration  0\n",
      "end_total_asset:1011396.6240000007\n",
      "Iteration  0\n",
      "end_total_asset:1011832.0100000006\n",
      "Iteration  0\n",
      "end_total_asset:1011228.8220000005\n",
      "Iteration  0\n",
      "end_total_asset:1012170.1320000006\n",
      "Iteration  0\n",
      "end_total_asset:1011576.0980000006\n",
      "Iteration  0\n",
      "end_total_asset:1011512.4860000004\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df2 = pd.read_csv('GU_dataa.csv')\n",
    "env2 = ForexEnv(df2)\n",
    "agent = Model()\n",
    "print(env2.reset())\n",
    "agent.Q_learning(env2, 100, alpha=0.1, exploration=0.9, discount=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_test = pd.read_csv(\"forex_data_2017.csv\").reset_index(drop=True)\n",
    "env_test = ForexEnv(df_test)\n",
    "print(env_test.reset())\n",
    "#agent.Q_learning(env_test, iterations=1, alpha=0, exploration=0, discount=0, debug=True)\n",
    "env_test.step(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#print(list(dict(agent.Q_values).items())[i] for i in range(len(dict(agent.Q_values))) if list(dict(agent.Q_values).items())[i][1] == 0)\n",
    "j = 0\n",
    "a = []\n",
    "f = open('qvalue_is_0.csv', 'w')\n",
    "f.truncate()\n",
    "f.close()\n",
    "for i in range(len(dict(agent.Q_values))):\n",
    "    Q_dict = list(dict(agent.Q_values).items())\n",
    "    if Q_dict[i][1] == 0:\n",
    "        a.append(Q_dict[i])\n",
    "        q_data = pd.DataFrame({i: [a[-1]]})\n",
    "        q_data.to_csv('qvalue_is_0.csv', mode='a', index=False, header=False)\n",
    "        j += 1\n",
    "print(j)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = []\n",
    "m = 100\n",
    "k = 10\n",
    "start = 0\n",
    "n = len(df)\n",
    "size = math.floor(n / k)\n",
    "df_test = pd.read_csv(\"forex_data_2017.csv\").reset_index(drop=True)\n",
    "env_test = ForexEnv(df_test)\n",
    "f = open('b.csv', 'w')\n",
    "f.truncate()\n",
    "f.close()\n",
    "\n",
    "for i in range(k):\n",
    "    if i == k - 1:\n",
    "        end = n\n",
    "    end = start + size\n",
    "    df_k = df.loc[start:end].reset_index(drop=True)\n",
    "    environment = ForexEnv(df_k)\n",
    "    environment.reset()\n",
    "    #print(df_k)\n",
    "    agent.Q_learning(environment, iterations=m)\n",
    "    #if i == k - 2 or i == k - 1:\n",
    "    if i >= 0:\n",
    "        agent.Q_learning(env_test, iterations=1, alpha=0, exploration=0, discount=0, debug=True)\n",
    "        plt.plot(env_test.asset_memory,'r')\n",
    "        a = 'png_test/account_value_test.png'\n",
    "        plt.savefig(a[:-4] + str(i) + '.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        agent.Q_learning(env_test, iterations=1, alpha=0, exploration=0, discount=0)\n",
    "    result.append(env_test.asset_memory[-1])\n",
    "    q_data = pd.DataFrame({i: [result[-1]]})\n",
    "    q_data.to_csv('b.csv', mode='a', index=False, header=False)\n",
    "    start += size\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df.loc[np.r_[10:20, 30:40],:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent.Q_learning(environment, iterations=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env2000 = ForexEnv(df)\n",
    "agent.Q_learning(env2000, iterations=1, alpha=0, exploration=0, discount=0, debug=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(environment.reset())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# environment.step(-1)\n",
    "print(environment.balance)\n",
    "print(environment.asset_memory)\n",
    "print(environment.state)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(agent.Q_values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent.Q_learning(environment, iterations=5, alpha=0, exploration=0, discount=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(environment.step(math.pi))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(environment.state)\n",
    "print(environment.balance)\n",
    "print(environment.asset_memory)\n",
    "print(environment.rewards_memory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(environment.state)\n",
    "print(environment.balance)\n",
    "print(environment.asset_memory)\n",
    "print(environment.rewards_memory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#saving the agent's q values\n",
    "Q_dict = dict(agent.Q_values)\n",
    "with open('test/100k_8maxscore_2datasets.pickle', 'wb') as handle:\n",
    "    pickle.dump(Q_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(Q_dict))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Q_dict = dict(agent.Q_values)\n",
    "keys = list(Q_dict.keys())\n",
    "reduce = [a[0] for a in keys]\n",
    "state = [a[0] for a in reduce]\n",
    "price = [a[0] for a in state]\n",
    "#print(price)\n",
    "print((1.0723, 12.7325, 2.0624) in state)\n",
    "#print(state)\n",
    "#print(Q_dict[(((1.1835, 0.0068, 8.7028, 0.34), 20), 0)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_2 = pd.read_csv('forex_data_2017.csv')\n",
    "df_2 = df_2.loc[::-1].reset_index(drop=True).head(1000)\n",
    "environment_2 = ForexEnv(df_2)\n",
    "print(environment_2.state)\n",
    "#agent_2 = Model()\n",
    "agent_2 = Model(load=\"Q_value_test2.pickle\")\n",
    "#print(dict(agent_2.Q_values))\n",
    "print(environment_2.reset())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(agent_2.Q_values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent.Q_learning(environment_2, iterations=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent.Q_learning(environment_2, iterations=1, alpha = 0, exploration = 0, discount = 0)\n",
    "#print(environment_2.rewards_memory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_3 = pd.read_csv('forex_data_2000.csv')\n",
    "df_3 = df_3.loc[::-1].reset_index(drop=True).tail(500).reset_index(drop=True)\n",
    "environment_3 = ForexEnv(df_3)\n",
    "environment_3.reset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df_3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent.Q_learning(environment_3, iterations=1, alpha=0, exploration=0, discount=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_with_indicators(df)\n",
    "print(df)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('pythonProject': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "interpreter": {
   "hash": "88d539b4520202eb5e4c6dfa8844d3212bffe2b772245135a1398c04deaa950e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}